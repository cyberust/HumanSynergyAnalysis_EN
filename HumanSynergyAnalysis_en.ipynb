{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMENi752W4525+6KbVzSrTb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyberust/HumanSynergyAnalysis_EN/blob/main/HumanSynergyAnalysis_en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtAzeUNITOd4",
        "outputId": "2fe7b94b-a997-4566-8462-0b405b10b088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Libraries installed successfully.\n",
            "✅ Libraries imported successfully.\n",
            "✅ Analysis configuration defined.\n",
            "--- Starting analysis pipeline ---\n",
            "--> Step 1: Preparing output directory: '/content/drive/MyDrive/synergy_semantic_analysis_20250620_231225'\n",
            "--> Step 2: Pausing for 8 seconds to ensure Google Drive synchronization...\n"
          ]
        }
      ],
      "source": [
        "# ======================================================================\n",
        "#\n",
        "#  Human Synergy Analysis System V3 - Final Stable Version (English)\n",
        "#\n",
        "#  Features:\n",
        "#  - Centralized parameter management via the CONFIG object.\n",
        "#  - Consistent execution via a single analysis pipeline.\n",
        "#  - Decoupled visualization and file saving to prevent resource issues.\n",
        "#\n",
        "# ======================================================================\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 1: Library Installation\n",
        "# ===============================================================\n",
        "!pip install sentence-transformers pandas numpy scipy networkx plotly scikit-learn --quiet\n",
        "print(\"✅ Libraries installed successfully.\")\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 2: Library Imports\n",
        "# ===============================================================\n",
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import time # Import time for adding delays\n",
        "\n",
        "from scipy.integrate import odeint\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from datetime import datetime\n",
        "from google.colab import drive\n",
        "print(\"✅ Libraries imported successfully.\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 3: Centralized Analysis Configuration\n",
        "# ===============================================================\n",
        "CONFIG = {\n",
        "    'data': {\n",
        "        'base_path': \"/content/drive/MyDrive/\",\n",
        "        'names': [\"arale_cohen\", \"yanay_geva\", \"yasuyuki_sakane\"],\n",
        "        'display_names': [\"Arale Cohen\", \"Yanay Geva\", \"Yasuyuki Sakane\"]\n",
        "    },\n",
        "    'profile_analysis': {\n",
        "        'embedding_model': 'all-MiniLM-L6-v2',\n",
        "        'experience_default': 10,\n",
        "        'network_keywords': ['network', 'ecosystem', 'connections', 'board member', 'partner'],\n",
        "        'network_multiplier': 20\n",
        "    },\n",
        "    'synergy_calculation': {\n",
        "        'weights': {\n",
        "            'complementarity': 0.5,\n",
        "            'experience': 0.2,\n",
        "            'network': 0.2\n",
        "        },\n",
        "        'diversity_bonus': 1.2,\n",
        "        'cultural_backgrounds': {'Arale Cohen': 'Western', 'Yanay Geva': 'Western', 'Yasuyuki Sakane': 'Eastern'}\n",
        "    },\n",
        "    'dynamic_model': {\n",
        "        'alpha': np.array([0.4, 0.35, 0.45]),\n",
        "        'beta_multiplier': 0.1,\n",
        "        'K': np.array([12.0, 12.0, 12.0]),\n",
        "        'initial_state': [1.0, 1.0, 1.0],\n",
        "        'time_horizon': 24\n",
        "    },\n",
        "    'game_theory': {\n",
        "        'synergy_value_multiplier': 5\n",
        "    },\n",
        "    'business_forecast': {\n",
        "        'revenue_base_multiplier': 10,\n",
        "        'revenue_synergy_multiplier': 5,\n",
        "        'innovation_synergy_multiplier': 10,\n",
        "    },\n",
        "    'output': {\n",
        "        'base_path': \"/content/drive/MyDrive/\",\n",
        "        'folder_prefix': \"synergy_semantic_analysis_\"\n",
        "    }\n",
        "}\n",
        "print(\"✅ Analysis configuration defined.\")\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 4: Definition of Analysis Classes\n",
        "# ===============================================================\n",
        "\n",
        "class DataLoader:\n",
        "    def __init__(self, config):\n",
        "        self.config = config['data']\n",
        "\n",
        "    def load_profiles(self):\n",
        "        # Check if already mounted and unmount if necessary\n",
        "        mountpoint = '/content/drive'\n",
        "        if os.path.exists(mountpoint) and os.path.ismount(mountpoint):\n",
        "            try:\n",
        "                drive.flush_and_unmount()\n",
        "                print(\"✅ Drive unmounted successfully.\")\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error during unmount: {e}\")\n",
        "\n",
        "        # Attempt to remove any residual files in the mountpoint\n",
        "        if os.path.exists(mountpoint):\n",
        "             try:\n",
        "                 os.system(f'rm -rf {mountpoint}/*')\n",
        "                 print(\"✅ Cleaned up mountpoint.\")\n",
        "             except Exception as e:\n",
        "                 print(f\"⚠️ Error during mountpoint cleanup: {e}\")\n",
        "\n",
        "        # Mount the drive\n",
        "        drive.mount(mountpoint, force_remount=True)\n",
        "        print(\"✅ Drive mounted successfully.\")\n",
        "\n",
        "        profiles = {}\n",
        "        for name, display_name in zip(self.config['names'], self.config['display_names']):\n",
        "            try:\n",
        "                with open(f\"{self.config['base_path']}{name}_profile.txt\", 'r', encoding='utf-8') as f:\n",
        "                    profiles[display_name] = f.read()\n",
        "            except FileNotFoundError:\n",
        "                profiles[display_name] = \"Profile data not available.\"\n",
        "        return profiles\n",
        "\n",
        "class SemanticProfileAnalyzer:\n",
        "    def __init__(self, config):\n",
        "        self.config = config['profile_analysis']\n",
        "        self.model = SentenceTransformer(self.config['embedding_model'])\n",
        "\n",
        "    def analyze(self, profiles_dict):\n",
        "        analysis_results = {}\n",
        "        names = list(profiles_dict.keys())\n",
        "        texts = list(profiles_dict.values())\n",
        "        embeddings = self.model.encode(texts, show_progress_bar=False)\n",
        "\n",
        "        for i, name in enumerate(names):\n",
        "            analysis_results[name] = {\n",
        "                'embedding': embeddings[i],\n",
        "                'experience_years': self._extract_experience(texts[i]),\n",
        "                'network_strength': self._extract_network_strength(texts[i])\n",
        "            }\n",
        "        return analysis_results\n",
        "\n",
        "    def _extract_experience(self, text):\n",
        "        matches = re.findall(r'(\\d+)\\+?\\s*years?', text.lower())\n",
        "        return max([int(m) for m in matches]) if matches else self.config['experience_default']\n",
        "\n",
        "    def _extract_network_strength(self, text):\n",
        "        score = sum(text.lower().count(k) for k in self.config['network_keywords'])\n",
        "        return min(score * self.config['network_multiplier'], 100)\n",
        "\n",
        "class SynergyCalculator:\n",
        "    def __init__(self, config):\n",
        "        self.config = config['synergy_calculation']\n",
        "\n",
        "    def calculate(self, analysis_data):\n",
        "        names = list(analysis_data.keys())\n",
        "        num_ppl = len(names)\n",
        "\n",
        "        embeddings = np.array([analysis_data[n]['embedding'] for n in names])\n",
        "        comp_matrix = 1 - cosine_similarity(embeddings)\n",
        "\n",
        "        experiences = [analysis_data[n]['experience_years'] for n in names]\n",
        "        exp_matrix = np.zeros((num_ppl, num_ppl))\n",
        "        for i, j in np.ndindex(exp_matrix.shape):\n",
        "            if i != j: exp_matrix[i, j] = np.exp(-0.1 * abs(experiences[i] - experiences[j]))\n",
        "\n",
        "        networks = [analysis_data[n]['network_strength'] for n in names]\n",
        "        net_matrix = np.zeros((num_ppl, num_ppl))\n",
        "        for i, j in np.ndindex(net_matrix.shape):\n",
        "            if i != j: net_matrix[i, j] = (networks[i] * networks[j]) / 10000.0\n",
        "\n",
        "        w = self.config['weights']\n",
        "        total_synergy = (w['complementarity'] * comp_matrix +\n",
        "                         w['experience'] * exp_matrix +\n",
        "                         w['network'] * net_matrix)\n",
        "\n",
        "        backgrounds = self.config['cultural_backgrounds']\n",
        "        for i, n1 in enumerate(names):\n",
        "            for j, n2 in enumerate(names):\n",
        "                if backgrounds.get(n1) != backgrounds.get(n2):\n",
        "                    total_synergy[i, j] *= self.config['diversity_bonus']\n",
        "\n",
        "        np.fill_diagonal(total_synergy, 0)\n",
        "        return {'total_synergy': total_synergy, 'skill_complementarity': comp_matrix}\n",
        "\n",
        "class DynamicSystemModel:\n",
        "    def __init__(self, config):\n",
        "        self.config = config['dynamic_model']\n",
        "\n",
        "    def simulate(self, synergy_matrix):\n",
        "        c = self.config\n",
        "        alpha, K = c['alpha'], c['K']\n",
        "        beta = synergy_matrix * c['beta_multiplier']\n",
        "        t = np.linspace(0, c['time_horizon'], c['time_horizon'] * 4)\n",
        "        solution = odeint(self._system_dynamics, c['initial_state'], t, args=(alpha, beta, K))\n",
        "        return t, solution\n",
        "\n",
        "    def _system_dynamics(self, state, t, alpha, beta, K):\n",
        "        x = np.array(state)\n",
        "        dxdt = (alpha * x + np.dot(beta, x)) * (1 - x / K)\n",
        "        return dxdt\n",
        "\n",
        "class GameTheoryAnalyzer:\n",
        "    def __init__(self, config):\n",
        "        self.config = config['game_theory']\n",
        "\n",
        "    def calculate_shapley(self, analysis_data, synergy_matrix):\n",
        "        \"\"\"Calculates Shapley values for each member.\"\"\"\n",
        "        from math import factorial\n",
        "        from itertools import combinations\n",
        "\n",
        "        names = list(analysis_data.keys())\n",
        "        n_players = len(names)\n",
        "        shapley_values = np.zeros(n_players)\n",
        "\n",
        "        # Prepare for contribution calculation\n",
        "        player_indices = list(range(n_players))\n",
        "        memo = {} # Use memoization to speed up calculations\n",
        "\n",
        "        for i in player_indices:\n",
        "            for coalition_size in range(n_players):\n",
        "                for coalition_tuple in combinations(player_indices, coalition_size):\n",
        "                    if i in coalition_tuple:\n",
        "                        continue\n",
        "\n",
        "                    # Calculate coalition value (using memoization)\n",
        "                    s_without_i = tuple(sorted(coalition_tuple))\n",
        "                    if s_without_i not in memo:\n",
        "                        memo[s_without_i] = self._get_coalition_value(s_without_i, analysis_data, synergy_matrix)\n",
        "\n",
        "                    s_with_i = tuple(sorted(list(s_without_i) + [i]))\n",
        "                    if s_with_i not in memo:\n",
        "                        memo[s_with_i] = self._get_coalition_value(s_with_i, analysis_data, synergy_matrix)\n",
        "\n",
        "                    marginal_contribution = memo[s_with_i] - memo[s_without_i]\n",
        "\n",
        "                    # Calculate coefficient and add to Shapley value\n",
        "                    weight = (factorial(coalition_size) * factorial(n_players - coalition_size - 1)) / factorial(n_players)\n",
        "                    shapley_values[i] += weight * marginal_contribution\n",
        "\n",
        "        return shapley_values\n",
        "\n",
        "    def _get_coalition_value(self, indices, analysis_data, synergy_matrix):\n",
        "        \"\"\"Calculates the value of a given coalition.\"\"\"\n",
        "        if not indices:\n",
        "            return 0\n",
        "\n",
        "        names = list(analysis_data.keys())\n",
        "\n",
        "        # V3.3 Fix: Base value is calculated from the magnitude (L2 norm) of the semantic vector.\n",
        "        # This reflects the richness or strength of an individual's profile.\n",
        "        base_value = sum(np.linalg.norm(analysis_data[names[i]]['embedding']) for i in indices)\n",
        "\n",
        "        # Calculate synergy value within the coalition\n",
        "        synergy_value = sum(synergy_matrix[i, j] for i in indices for j in indices if i != j)\n",
        "\n",
        "        # Return the final coalition value\n",
        "        return base_value + synergy_value * self.config['synergy_value_multiplier']\n",
        "\n",
        "class VisualizationGenerator:\n",
        "    def __init__(self, config):\n",
        "        self.config = config['data']\n",
        "\n",
        "    def generate_all_figures(self, results):\n",
        "        figures = {}\n",
        "        names = self.config['display_names']\n",
        "\n",
        "        figures['synergy_heatmap'] = px.imshow(results['synergy']['total_synergy'], x=names, y=names, text_auto='.3f',\n",
        "                                               labels=dict(x=\"Member\", y=\"Member\", color=\"Synergy Score\"), color_continuous_scale='Blues',\n",
        "                                               title='V3: Overall Synergy Matrix')\n",
        "\n",
        "        df_growth = pd.DataFrame(results['simulation_solution'], columns=names)\n",
        "        df_growth['Time (Months)'] = results['simulation_time_axis']\n",
        "        figures['growth_trajectory'] = px.line(df_growth, x='Time (Months)', y=names, title='V3: Dynamic Growth Trajectory Simulation')\n",
        "\n",
        "        df_biz = results['business_forecast']\n",
        "        fig_biz = px.line(df_biz, x='time_months', y=['revenue_growth_rate', 'innovation_index'],\n",
        "                          title='V3: Business Metrics Forecast', facet_row=\"variable\", labels={\"variable\":\"\", \"time_months\": \"Time (Months)\"})\n",
        "        fig_biz.update_yaxes(matches=None)\n",
        "        figures['business_dashboard'] = fig_biz\n",
        "\n",
        "        figures['shapley_values'] = px.bar(x=names, y=results['shapley_values'], text_auto='.2f',\n",
        "                                           labels={'x':'Member', 'y':'Value Contribution'}, title='V3: Value Contribution (Shapley Values)')\n",
        "\n",
        "        G = nx.from_numpy_array(results['synergy']['total_synergy'])\n",
        "        pos = nx.spring_layout(G, k=1.5, iterations=50)\n",
        "        edge_traces = [go.Scatter(x=[pos[edge[0]][0], pos[edge[1]][0], None], y=[pos[edge[0]][1], pos[edge[1]][1], None],\n",
        "                                  mode='lines', line=dict(width=edge[2]['weight']*10, color='#888'),\n",
        "                                  hoverinfo='text', text=f\"Synergy: {edge[2]['weight']:.3f}\")\n",
        "                       for edge in G.edges(data=True)]\n",
        "        node_trace = go.Scatter(x=[pos[n][0] for n in G.nodes()], y=[pos[n][1] for n in G.nodes()], mode='markers+text',\n",
        "                                text=[names[i] for i in G.nodes()], textposition=\"top center\",\n",
        "                                marker=dict(size=[results['analysis'][n]['network_strength']/5 for n in names],\n",
        "                                            color=['#FF6B6B', '#4ECDC4', '#45B7D1']))\n",
        "        fig_net = go.Figure(data=edge_traces + [node_trace], layout=go.Layout(title='V3: Team Interaction Network', showlegend=False,\n",
        "                                                                             xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                                                                             yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)))\n",
        "        figures['network_graph'] = fig_net\n",
        "\n",
        "        return figures\n",
        "\n",
        "# ===============================================================\n",
        "# STEP 5: Definition and Execution of the Analysis Pipeline\n",
        "# ===============================================================\n",
        "\n",
        "class AnalysisPipeline:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.data_loader = DataLoader(config)\n",
        "        self.profile_analyzer = SemanticProfileAnalyzer(config)\n",
        "        self.synergy_calculator = SynergyCalculator(config)\n",
        "        self.dynamic_model = DynamicSystemModel(config)\n",
        "        self.game_theory_analyzer = GameTheoryAnalyzer(config)\n",
        "        self.viz_generator = VisualizationGenerator(config)\n",
        "        self.run_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    def run(self):\n",
        "        print(\"--- Starting analysis pipeline ---\")\n",
        "\n",
        "        # Step 1: Prepare output folder\n",
        "        output_folder_path = os.path.join(self.config['output']['base_path'], f\"{self.config['output']['folder_prefix']}{self.run_timestamp}\")\n",
        "        print(f\"--> Step 1: Preparing output directory: '{output_folder_path}'\")\n",
        "        os.makedirs(output_folder_path, exist_ok=True)\n",
        "\n",
        "        # Step 2: Wait for Google Drive sync (set longer).\n",
        "        # This wait time is key to preventing file save errors.\n",
        "        wait_time = 8\n",
        "        print(f\"--> Step 2: Pausing for {wait_time} seconds to ensure Google Drive synchronization...\")\n",
        "        time.sleep(wait_time)\n",
        "        print(\"   ...Synchronization pause complete.\")\n",
        "\n",
        "        # Step 3: Perform analysis tasks\n",
        "        print(\"--> Step 3: Starting main analysis tasks...\")\n",
        "        profiles = self.data_loader.load_profiles()\n",
        "        print(f\"✅ Loaded {len(profiles)} profiles.\")\n",
        "\n",
        "        analysis_data = self.profile_analyzer.analyze(profiles)\n",
        "        print(\"✅ Profile analysis (semantic embedding) complete.\")\n",
        "\n",
        "        synergy_results = self.synergy_calculator.calculate(analysis_data)\n",
        "        print(\"✅ Synergy matrix calculation complete.\")\n",
        "\n",
        "        time_axis, solution = self.dynamic_model.simulate(synergy_results['total_synergy'])\n",
        "        print(\"✅ Dynamic growth simulation complete.\")\n",
        "\n",
        "        shapley_values = self.game_theory_analyzer.calculate_shapley(analysis_data, synergy_results['total_synergy'])\n",
        "        print(\"✅ Shapley value calculation complete.\")\n",
        "\n",
        "        c_biz = self.config['business_forecast']\n",
        "        perf_data = [{'time_months': time_axis[t],\n",
        "                      'revenue_growth_rate': np.sum(solution[t]) * c_biz['revenue_base_multiplier'] + (np.sum(synergy_results['total_synergy'] * np.outer(solution[t], solution[t]))/2) * c_biz['revenue_synergy_multiplier'],\n",
        "                      'innovation_index': (np.sum(synergy_results['total_synergy'] * np.outer(solution[t], solution[t]))/2) * c_biz['innovation_synergy_multiplier']}\n",
        "                     for t in range(len(time_axis))]\n",
        "        business_forecast_df = pd.DataFrame(perf_data)\n",
        "        print(\"✅ Business metrics forecast complete.\")\n",
        "\n",
        "        results = {'config': self.config, 'profiles': profiles, 'analysis': analysis_data, 'synergy': synergy_results,\n",
        "                   'simulation_time_axis': time_axis, 'simulation_solution': solution, 'shapley_values': shapley_values,\n",
        "                   'business_forecast': business_forecast_df}\n",
        "\n",
        "        # Step 4: Generate Visualization\n",
        "        print(\"--> Step 4: Generating graph objects...\")\n",
        "        results['figures'] = self.viz_generator.generate_all_figures(results)\n",
        "        print(\"✅ All graph figure objects generated.\")\n",
        "\n",
        "        # Step 5: Save outputs\n",
        "        print(\"--> Step 5: Saving artifacts...\")\n",
        "        self._save_artifacts(results, output_folder_path)\n",
        "\n",
        "        print(\"\\n--- ✅ Pipeline execution complete ---\")\n",
        "        return results\n",
        "\n",
        "    def _create_combined_html(self, figures_dict):\n",
        "        html_string = \"\"\"\n",
        "        <html><head><title>V3 Human Synergy Analysis Dashboard</title>\n",
        "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>\n",
        "        <style>body{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,'Helvetica Neue',Arial,sans-serif;margin:2em;} .chart-container{border:1px solid #e0e0e0;border-radius:8px;margin-bottom:25px;padding:15px;box-shadow:0 2px 4px rgba(0,0,0,0.05);} h1{color:#1a1a1a;} h2{color:#3a3a3a;border-bottom:2px solid #f0f0f0;padding-bottom:8px;}</style>\n",
        "        </head><body><h1>Human Synergy Analysis Dashboard V3</h1>\"\"\"\n",
        "        for name, fig in figures_dict.items():\n",
        "            title = fig.layout.title.text if fig.layout.title.text else name\n",
        "            html_string += f'<div class=\"chart-container\"><h2>{title}</h2><div id=\"{name}\" style=\"width:100%;min-height:500px;\"></div></div>'\n",
        "        html_string += \"<script>\\n\"\n",
        "        for name, fig in figures_dict.items():\n",
        "            fig_json = fig.to_json()\n",
        "            html_string += f\"    Plotly.newPlot('{name}', {fig_json});\\n\"\n",
        "        html_string += \"</script></body></html>\"\n",
        "        return html_string\n",
        "\n",
        "    def _save_artifacts(self, results, output_folder_path):\n",
        "        # Save the integrated HTML dashboard\n",
        "        combined_html_content = self._create_combined_html(results['figures'])\n",
        "        dashboard_filename = \"synergy_dashboard_V3.html\"\n",
        "        dashboard_full_path = os.path.join(output_folder_path, dashboard_filename)\n",
        "        try:\n",
        "            with open(dashboard_full_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(combined_html_content)\n",
        "            print(f\"✅ Combined dashboard saved as HTML to '{dashboard_full_path}'\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error saving combined dashboard: {e}\")\n",
        "\n",
        "        # Save Reports\n",
        "        names = self.config['data']['display_names']\n",
        "        report_str = f\"# Human Synergy Analysis Report V3 ({self.run_timestamp})\\n\\n\"\n",
        "        report_str += \"## 1. Overall Synergy Analysis\\n\" + \"The overall synergy matrix is as follows:\\n\" + pd.DataFrame(results['synergy']['total_synergy'], columns=names, index=names).to_markdown() + \"\\n\\n\"\n",
        "        report_str += \"## 2. Skill Complementarity Analysis (Semantic-based)\\n\" + \"Semantic complementarity of profiles (closer to 1 is more complementary):\\n\" + pd.DataFrame(results['synergy']['skill_complementarity'], columns=names, index=names).to_markdown() + \"\\n\\n\"\n",
        "        report_str += \"## 3. Value Contribution Analysis (Shapley Values)\\n\" + \"Each member's contribution to the total value created by the team is as follows:\\n\" + \"\".join([f\"- {name}: {val:.3f}\\n\" for name, val in zip(names, results['shapley_values'])]) + \"\\n\"\n",
        "        report_str += \"## 4. Summary\\n\" + \"This analysis (V3) calculates more realistic synergy and contribution values by directly comparing the semantic content of each member's profile.\\n\" + \"Notably, skill complementarity is a result of capturing the nuances of the entire text, rather than simple keyword matching.\\n\"\n",
        "        report_filename = \"analysis_report_V3.md\"\n",
        "        report_full_path = os.path.join(output_folder_path, report_filename)\n",
        "        try:\n",
        "            with open(report_full_path, 'w', encoding='utf-8') as f:\n",
        "                f.write(report_str)\n",
        "            print(f\"✅ Detailed analysis report saved to '{report_full_path}'\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error saving detailed analysis report: {e}\")\n",
        "\n",
        "# Execute the pipeline\n",
        "pipeline = AnalysisPipeline(CONFIG)\n",
        "results = pipeline.run()"
      ]
    }
  ]
}